{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW4tb9mffYaKMKnU8JyHpR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likezhu7-prog/Classification-Assignment-/blob/main/Copy_of_model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 0. Imports\n",
        "# ===============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OeC8d7jZZg9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 1. Load dataset\n",
        "# ===============================================\n",
        "df = pd.read_csv(\"cancer_cleaned_trimmed.csv\")\n",
        "X = df[\"cleaned_text\"].astype(str)\n",
        "y = df[\"label\"].astype(int)"
      ],
      "metadata": {
        "id": "t_YHZaZCZl29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 2. Train / Validation / Test split\n",
        "# ===============================================\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.40, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Validation size:\", len(X_val))\n",
        "print(\"Test size:\", len(X_test))"
      ],
      "metadata": {
        "id": "Fbd0tRA8Z1eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 3. TF-IDF + Traditional Models (10-fold CV)\n",
        "# ===============================================\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=3,\n",
        "    max_df=0.9,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"SVM (LinearSVC)\": LinearSVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"kNN\": KNeighborsClassifier(n_neighbors=5, metric=\"cosine\"),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective=\"multi:softmax\",\n",
        "        num_class=len(np.unique(y)),\n",
        "        eval_metric=\"mlogloss\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"SGD\": SGDClassifier(loss=\"hinge\", random_state=42)\n",
        "}\n",
        "\n",
        "pipelines = {\n",
        "    name: Pipeline([\n",
        "        (\"tfidf\", tfidf),\n",
        "        (\"clf\", model)\n",
        "    ])\n",
        "    for name, model in models.items()\n",
        "}\n",
        "\n",
        "def evaluate_models(pipelines, X_train, y_train, cv=10):\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    results = []\n",
        "    confusion_mats = {}\n",
        "\n",
        "    for name, pipe in pipelines.items():\n",
        "        print(f\"\\n=== Evaluating {name} ===\")\n",
        "\n",
        "        y_pred = cross_val_predict(pipe, X_train, y_train, cv=skf, n_jobs=-1)\n",
        "\n",
        "        acc = accuracy_score(y_train, y_pred)\n",
        "        prec = precision_score(y_train, y_pred, average=\"macro\")\n",
        "        f1 = f1_score(y_train, y_pred, average=\"macro\")\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy\": acc,\n",
        "            \"Precision_macro\": prec,\n",
        "            \"F1_macro\": f1\n",
        "        })\n",
        "\n",
        "        confusion_mats[name] = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print(f\"Macro Precision: {prec:.4f}\")\n",
        "        print(f\"Macro F1: {f1:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results), confusion_mats\n",
        "\n",
        "results_df, confusion_mats = evaluate_models(pipelines, X_train, y_train)\n",
        "print(\"\\n=== Traditional Models Summary ===\")\n",
        "print(results_df.sort_values(by=\"F1_macro\", ascending=False))"
      ],
      "metadata": {
        "id": "s9SsmVIaZ937"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 4. BERT: Prepare model\n",
        "# ===============================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "bert_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
        "bert_model = AutoModel.from_pretrained(bert_name).to(device)\n",
        "bert_model.eval()"
      ],
      "metadata": {
        "id": "dIs1vkJabBy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 5. BERT Encoding Function\n",
        "# ===============================================\n",
        "def bert_encode(texts, batch_size=16, max_length=256):\n",
        "    all_embeddings = []\n",
        "    if not isinstance(texts, (list, tuple)):\n",
        "        texts = list(texts)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i + batch_size]\n",
        "            enc = tokenizer(\n",
        "                batch, padding=True, truncation=True,\n",
        "                max_length=max_length, return_tensors=\"pt\"\n",
        "            )\n",
        "            enc = {k: v.to(device) for k, v in enc.items()}\n",
        "            outputs = bert_model(**enc)\n",
        "            cls_vec = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_embeddings.append(cls_vec)\n",
        "\n",
        "    return np.vstack(all_embeddings)"
      ],
      "metadata": {
        "id": "KDwuIqDZbFS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 6. BERT encode Train / Val / Test\n",
        "# ===============================================\n",
        "print(\"\\nEncoding texts using BERT...\")\n",
        "X_train_bert = bert_encode(X_train)\n",
        "X_val_bert = bert_encode(X_val)\n",
        "X_test_bert = bert_encode(X_test)\n",
        "\n",
        "print(\"BERT Train:\", X_train_bert.shape)\n",
        "print(\"BERT Val:\", X_val_bert.shape)\n",
        "print(\"BERT Test:\", X_test_bert.shape)"
      ],
      "metadata": {
        "id": "-enTI0sEbL40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 7. BERT + Logistic Regression\n",
        "# ===============================================\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "clf_bert = LogisticRegression(max_iter=1000, n_jobs=-1, multi_class=\"multinomial\")\n",
        "clf_bert.fit(X_train_bert, y_train)\n",
        "\n",
        "y_val_pred = clf_bert.predict(X_val_bert)\n",
        "val_acc = accuracy_score(y_val, y_val_pred)\n",
        "val_precision = precision_score(y_val, y_val_pred, average=\"macro\")\n",
        "val_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
        "\n",
        "print(\"\\n=== BERT Validation Results ===\")\n",
        "print(\"Validation Accuracy:\", round(val_acc, 4))\n",
        "print(\"Validation Macro Precision:\", round(val_precision, 4))\n",
        "print(\"Validation Macro F1:\", round(val_f1, 4))\n",
        "print(\"\\nValidation classification report:\")\n",
        "print(classification_report(y_val, y_val_pred, digits=3))\n"
      ],
      "metadata": {
        "id": "x9K90S7PbPQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 8. Final training on Train+Val, test on Test (BERT)\n",
        "# ===============================================\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "X_trainval_bert = np.vstack([X_train_bert, X_val_bert])\n",
        "y_trainval = pd.concat([y_train, y_val])\n",
        "\n",
        "clf_bert_final = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    n_jobs=-1,\n",
        "    multi_class=\"multinomial\"\n",
        ")\n",
        "clf_bert_final.fit(X_trainval_bert, y_trainval)\n",
        "\n",
        "# Test evaluation for BERT\n",
        "y_test_pred_bert = clf_bert_final.predict(X_test_bert)\n",
        "\n",
        "bert_test_acc = accuracy_score(y_test, y_test_pred_bert)\n",
        "bert_test_precision = precision_score(y_test, y_test_pred_bert, average=\"macro\")\n",
        "bert_test_f1 = f1_score(y_test, y_test_pred_bert, average=\"macro\")\n",
        "\n",
        "print(\"\\n=== BERT Test Results ===\")\n",
        "print(\"Test Accuracy:\", round(bert_test_acc, 4))\n",
        "print(\"Test Macro Precision:\", round(bert_test_precision, 4))\n",
        "print(\"Test Macro F1:\", round(bert_test_f1, 4))\n",
        "print(\"\\nClassification Report (Test):\")\n",
        "print(classification_report(y_test, y_test_pred_bert, digits=3))\n",
        "\n"
      ],
      "metadata": {
        "id": "CFb8oApabSKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# 9. Model Selection Table (for choosing champion model)\n",
        "# ===============================================\n",
        "\n",
        "# Traditional models: 10-fold CV on Train\n",
        "# BERT: performance on Validation set\n",
        "\n",
        "model_selection_df = results_df.copy()\n",
        "model_selection_df[\"Source\"] = \"CV on Train\"\n",
        "\n",
        "bert_selection_row = {\n",
        "    \"Model\": \"BERT + Logistic Regression\",\n",
        "    \"Accuracy\": val_acc,\n",
        "    \"Precision_macro\": val_precision,\n",
        "    \"F1_macro\": val_f1,\n",
        "    \"Source\": \"Validation\"\n",
        "}\n",
        "\n",
        "model_selection_df = pd.concat(\n",
        "    [model_selection_df, pd.DataFrame([bert_selection_row])],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "print(\"\\n=== Model Selection ===\")\n",
        "print(model_selection_df.sort_values(by=\"F1_macro\", ascending=False))\n"
      ],
      "metadata": {
        "id": "z0LxkaPfbYgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Final Testing for Champion Model: SVM =====\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "svm_champion = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        ngram_range=(1,2),\n",
        "        min_df=3,\n",
        "        max_df=0.9,\n",
        "        sublinear_tf=True\n",
        "    )),\n",
        "    (\"clf\", LinearSVC())\n",
        "])\n",
        "\n",
        "# Train + Validation\n",
        "X_trainval = pd.concat([X_train, X_val])\n",
        "y_trainval = pd.concat([y_train, y_val])\n",
        "\n",
        "# Train champion\n",
        "svm_champion.fit(X_trainval, y_trainval)\n",
        "\n",
        "# Final Test predictions\n",
        "y_test_pred_svm = svm_champion.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report\n",
        "\n",
        "test_acc_svm = accuracy_score(y_test, y_test_pred_svm)\n",
        "test_precision_svm = precision_score(y_test, y_test_pred_svm, average=\"macro\")\n",
        "test_f1_svm = f1_score(y_test, y_test_pred_svm, average=\"macro\")\n",
        "\n",
        "print(\"=== Final Test Results: SVM (Champion Model) ===\")\n",
        "print(\"Test Accuracy:\", test_acc_svm)\n",
        "print(\"Test Macro Precision:\", test_precision_svm)\n",
        "print(\"Test Macro F1:\", test_f1_svm)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_test_pred_svm, digits=3))\n"
      ],
      "metadata": {
        "id": "sByr-P-pmm9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Confusion Matrix for SVM =====\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred_svm)\n",
        "\n",
        "class_names = [\"Colon_Cancer\", \"Liver_Cancer\", \"Lung_Cancer\", \"Stomach_Cancer\", \"Thyroid_Cancer\"]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fn_IqZEx20Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8E_WsMxngNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}