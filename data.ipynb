{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e882f7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stomach_Cancer.csv: 已写入 cleaned_text 列并保存，第一列为序号，共 200 行\n",
            "Liver_Cancer.csv: 已写入 cleaned_text 列并保存，第一列为序号，共 200 行\n"
          ]
        }
      ],
      "source": [
        "# 对 Stomach_Cancer.csv 和 Liver_Cancer.csv 做同样的文本清洗（与 alldata 相同：正则去 DOI/序号 → 小写去标点数字 → NLTK 停用词）\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return ''\n",
        "    s = text.strip()\n",
        "    s = s.replace('\"', '')\n",
        "    s = re.sub(r'^\\s*\\d+\\.\\s*', '', s)\n",
        "    s = re.sub(r'\\b10\\.\\d{4}/[^\\s]+', '', s)\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    words = [w for w in s.split() if w not in stop_words and len(w) > 0]\n",
        "    return ' '.join(words)\n",
        "\n",
        "for fname in ['Stomach_Cancer.csv', 'Liver_Cancer.csv']:\n",
        "    df = pd.read_csv(fname, encoding='utf-8', on_bad_lines='skip')\n",
        "    text_col = 'text' if 'text' in df.columns else ('摘要' if '摘要' in df.columns else None)\n",
        "    if text_col is not None:\n",
        "        df['cleaned_text'] = df[text_col].astype(str).apply(clean_text)\n",
        "        df = df.drop(columns=[text_col], errors='ignore')\n",
        "    # 第一列改为序号 1, 2, 3, ...\n",
        "    first_col = df.columns[0]\n",
        "    df[first_col] = range(1, len(df) + 1)\n",
        "    df.rename(columns={first_col: '序号'}, inplace=True)\n",
        "    df.to_csv(fname, index=False, encoding='utf-8')\n",
        "    print(f'{fname}: 已写入 cleaned_text 列并保存，第一列为序号，共 {len(df)} 行')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e23e868",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170 词以上共 200 行，已保留前 200 行并保存。\n"
          ]
        }
      ],
      "source": [
        "# Liver_Cancer.csv：删除 170 词以下的行，再从剩余行中只保留 200 行\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Liver_Cancer.csv', encoding='utf-8', on_bad_lines='skip')\n",
        "counts = df['cleaned_text'].fillna('').astype(str).str.split().str.len()\n",
        "df = df[counts > 170]   # 只保留 170 词以上的行\n",
        "n_after_filter = len(df)\n",
        "df = df.head(200)       # 只留 200 行（取前 200 行）\n",
        "df['序号'] = range(1, len(df) + 1)\n",
        "df.to_csv('Liver_Cancer.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(f'170 词以上共 {n_after_filter} 行，已保留前 200 行并保存。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "35b892dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已保留 120 词以上的 200 行并保存。\n"
          ]
        }
      ],
      "source": [
        "# Stomach_Cancer.csv：只保留 120 词以上的 200 行，其余删除\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('Stomach_Cancer.csv', encoding='utf-8', on_bad_lines='skip')\n",
        "counts = df['cleaned_text'].fillna('').astype(str).str.split().str.len()\n",
        "df = df[counts > 120]   # 只保留 120 词以上的行（共 200 行）\n",
        "df['序号'] = range(1, len(df) + 1)\n",
        "df.to_csv('Stomach_Cancer.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(f'已保留 120 词以上的 {len(df)} 行并保存。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730e654e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已删除低于 500 词的行，保留 1154 行并保存。\n",
            "label\n",
            "Colon_Cancer      395\n",
            "Lung_Cancer       359\n",
            "Thyroid_Cancer    400\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：删除低于 500 词的行\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "text_col = df.columns[2]\n",
        "counts = df[text_col].fillna('').astype(str).str.split().str.len()\n",
        "df = df[counts >= 500]\n",
        "df[df.columns[0]] = range(1, len(df) + 1)\n",
        "df.to_csv(fname, index=False, encoding='utf-8')\n",
        "\n",
        "print(f'已删除低于 500 词的行，保留 {len(df)} 行并保存。')\n",
        "print(df[df.columns[1]].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d034b72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第三列每行已截断为最多 1000 词，已保存。共 1154 行\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：第三列每行只保留前 1000 词\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "text_col = df.columns[2]\n",
        "df[text_col] = df[text_col].fillna('').astype(str).apply(lambda s: ' '.join(s.split()[:1000]))\n",
        "df.to_csv(fname, index=False, encoding='utf-8')\n",
        "\n",
        "print(f'第三列每行已截断为最多 1000 词，已保存。共 {len(df)} 行')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ca8d58",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "每个类别已保留 400 行，共 1154 行并保存。\n",
            "label\n",
            "Colon_Cancer      395\n",
            "Lung_Cancer       359\n",
            "Thyroid_Cancer    400\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/var/folders/8x/gqvljhg13m12gzcwf08svj3m0000gn/T/ipykernel_29128/3010071658.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(label_col, group_keys=False).apply(lambda g: g.head(400)).reset_index(drop=True)\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：每个类别只保留 400 行\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "label_col = df.columns[1]\n",
        "df = df.groupby(label_col, group_keys=False).apply(lambda g: g.head(400)).reset_index(drop=True)\n",
        "df[df.columns[0]] = range(1, len(df) + 1)\n",
        "df.to_csv(fname, index=False, encoding='utf-8')\n",
        "\n",
        "print(f'每个类别已保留 400 行，共 {len(df)} 行并保存。')\n",
        "print(df[label_col].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6360467",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第三列已清洗：小写、去标点/数字/特殊字符、去 NLTK 停用词，已保存。\n",
            "共 1154 行\n",
            "示例前 80 字: bacteroides fragilis b fragilis produce biofilm colonisation intestinal tract ca ...\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：文本清洗（小写、去标点数字特殊字符、去 NLTK 停用词）\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except:\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return ''\n",
        "    s = text.strip().lower()\n",
        "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    words = [w for w in s.split() if w not in stop_words and len(w) > 0]\n",
        "    return ' '.join(words)\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "text_col = df.columns[2]\n",
        "df[text_col] = df[text_col].fillna('').astype(str).apply(clean_text)\n",
        "df.to_csv(fname, index=False, encoding='utf-8')\n",
        "\n",
        "print('第三列已清洗：小写、去标点/数字/特殊字符、去 NLTK 停用词，已保存。')\n",
        "print('共', len(df), '行')\n",
        "print('示例前 80 字:', df[text_col].iloc[0][:80], '...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0a07a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "列名已改为：序号, label, cleaned_text，已保存。\n",
            "当前列名: ['序号', 'label', 'cleaned_text']\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：列名改成与 Liver_Cancer.csv 一致（序号, label, cleaned_text）\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "df.columns = ['序号', 'label', 'cleaned_text']\n",
        "df.to_csv(fname, index=False, encoding='utf-8')\n",
        "\n",
        "print('列名已改为：序号, label, cleaned_text，已保存。')\n",
        "print('当前列名:', list(df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd728e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colon_Cancer.csv: 395 行\n",
            "Lung_Cancer.csv: 359 行\n",
            "Thyroid_Cancer.csv: 400 行\n",
            "三个类别已分别保存为 Colon_Cancer.csv, Lung_Cancer.csv, Thyroid_Cancer.csv\n"
          ]
        }
      ],
      "source": [
        "# alldata_1_for_kaggle 2.csv：按 label 分成三个新文档\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'alldata_1_for_kaggle 2.csv'\n",
        "df = pd.read_csv(fname, encoding='utf-8', encoding_errors='replace', on_bad_lines='skip')\n",
        "label_col = 'label' if 'label' in df.columns else df.columns[1]\n",
        "\n",
        "for label in df[label_col].unique():\n",
        "    sub = df[df[label_col] == label].copy()\n",
        "    sub['序号'] = range(1, len(sub) + 1)\n",
        "    out_name = f'{label}.csv'\n",
        "    sub.to_csv(out_name, index=False, encoding='utf-8')\n",
        "    print(f'{out_name}: {len(sub)} 行')\n",
        "\n",
        "print('三个类别已分别保存为 Colon_Cancer.csv, Lung_Cancer.csv, Thyroid_Cancer.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a664165e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "未找到 livercancer.csv，跳过\n",
            "未找到 stomachcancer.csv，跳过\n",
            "改名完成。\n"
          ]
        }
      ],
      "source": [
        "# 将 livercancer.csv、stomachcancer.csv 改名为与 Lung_Cancer.csv 同格式（X_Cancer.csv）\n",
        "import os\n",
        "\n",
        "renames = [\n",
        "    ('livercancer.csv', 'Liver_Cancer.csv'),\n",
        "    ('stomachcancer.csv', 'Stomach_Cancer.csv'),\n",
        "]\n",
        "for old_name, new_name in renames:\n",
        "    if os.path.exists(old_name):\n",
        "        os.rename(old_name, new_name)\n",
        "        print(f'{old_name} → {new_name}')\n",
        "    else:\n",
        "        print(f'未找到 {old_name}，跳过')\n",
        "print('改名完成。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb20bdc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colon_Cancer.csv: 已删除 {'cancers', 'colon', 'cancer'}，已保存。\n",
            "Liver_Cancer.csv: 已删除 {'liver', 'cancer', 'cancers'}，已保存。\n",
            "Lung_Cancer.csv: 已删除 {'lung', 'cancer', 'cancers'}，已保存。\n",
            "Stomach_Cancer.csv: 已删除 {'cancers', 'cancer', 'stomach'}，已保存。\n",
            "Thyroid_Cancer.csv: 已删除 {'cancers', 'cancer', 'thyroid'}，已保存。\n",
            "五个文件第三列病名词已删除完成。\n"
          ]
        }
      ],
      "source": [
        "# 五个 CSV 第三列分别删除对应病名词（整词）\n",
        "import pandas as pd\n",
        "\n",
        "config = [\n",
        "    ('Colon_Cancer.csv', {'colon', 'cancer', 'cancers'}),\n",
        "    ('Liver_Cancer.csv', {'liver', 'cancer', 'cancers'}),\n",
        "    ('Lung_Cancer.csv', {'lung', 'cancer', 'cancers'}),\n",
        "    ('Stomach_Cancer.csv', {'stomach', 'cancer', 'cancers'}),\n",
        "    ('Thyroid_Cancer.csv', {'thyroid', 'cancer', 'cancers'}),\n",
        "]\n",
        "\n",
        "for fname, remove_words in config:\n",
        "    try:\n",
        "        df = pd.read_csv(fname, encoding='utf-8', on_bad_lines='skip')\n",
        "    except FileNotFoundError:\n",
        "        print(f'未找到 {fname}，跳过')\n",
        "        continue\n",
        "    text_col = df.columns[2]\n",
        "    df[text_col] = df[text_col].fillna('').astype(str).apply(\n",
        "        lambda s: ' '.join(w for w in s.split() if w not in remove_words)\n",
        "    )\n",
        "    df.to_csv(fname, index=False, encoding='utf-8')\n",
        "    print(f'{fname}: 已删除 {remove_words}，已保存。')\n",
        "\n",
        "print('五个文件第三列病名词已删除完成。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3e5018",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colon_Cancer.csv: 第三列每行词数 — 最少=557, 最多=776, 平均=663.0\n",
            "Liver_Cancer.csv: 第三列每行词数 — 最少=133, 最多=394, 平均=207.9\n",
            "Lung_Cancer.csv: 第三列每行词数 — 最少=453, 最多=860, 平均=625.0\n",
            "Stomach_Cancer.csv: 第三列每行词数 — 最少=96, 最多=517, 平均=146.2\n",
            "Thyroid_Cancer.csv: 第三列每行词数 — 最少=590, 最多=776, 平均=661.4\n",
            "\n",
            "汇总表（第三列每行的词数）:\n",
            "                文件  行数  第三列每行最少(词)  第三列每行最多(词)  第三列每行平均(词)  第三列每行中位数(词)\n",
            "  Colon_Cancer.csv 395         557         776       663.0          662\n",
            "  Liver_Cancer.csv 200         133         394       207.9          197\n",
            "   Lung_Cancer.csv 359         453         860       625.0          624\n",
            "Stomach_Cancer.csv 200          96         517       146.2          136\n",
            "Thyroid_Cancer.csv 400         590         776       661.4          656\n"
          ]
        }
      ],
      "source": [
        "# 统计五个文件第三列每行的词数（按空格分词）\n",
        "import pandas as pd\n",
        "\n",
        "files = ['Colon_Cancer.csv', 'Liver_Cancer.csv', 'Lung_Cancer.csv', 'Stomach_Cancer.csv', 'Thyroid_Cancer.csv']\n",
        "text_col_name = 'cleaned_text'\n",
        "\n",
        "rows = []\n",
        "for fname in files:\n",
        "    try:\n",
        "        df = pd.read_csv(fname, encoding='utf-8', on_bad_lines='skip')\n",
        "    except FileNotFoundError:\n",
        "        print(f'未找到 {fname}，跳过')\n",
        "        continue\n",
        "    col = text_col_name if text_col_name in df.columns else df.columns[2]\n",
        "    # 第三列每行的词数\n",
        "    counts = df[col].fillna('').astype(str).str.split().str.len()\n",
        "    rows.append({\n",
        "        '文件': fname,\n",
        "        '行数': len(df),\n",
        "        '第三列每行最少(词)': int(counts.min()),\n",
        "        '第三列每行最多(词)': int(counts.max()),\n",
        "        '第三列每行平均(词)': round(counts.mean(), 1),\n",
        "        '第三列每行中位数(词)': int(counts.median()),\n",
        "    })\n",
        "    print(f'{fname}: 第三列每行词数 — 最少={counts.min()}, 最多={counts.max()}, 平均={counts.mean():.1f}')\n",
        "\n",
        "summary = pd.DataFrame(rows)\n",
        "print('\\n汇总表（第三列每行的词数）:')\n",
        "print(summary.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53f2986",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colon_Cancer.csv: 第三列已截断为 96 词，保留 200 行，已保存。\n",
            "Liver_Cancer.csv: 第三列已截断为 96 词，保留 200 行，已保存。\n",
            "Lung_Cancer.csv: 第三列已截断为 96 词，保留 200 行，已保存。\n",
            "Stomach_Cancer.csv: 第三列已截断为 96 词，保留 200 行，已保存。\n",
            "Thyroid_Cancer.csv: 第三列已截断为 96 词，保留 200 行，已保存。\n",
            "五个文件处理完成。\n"
          ]
        }
      ],
      "source": [
        "# 五个文件：第三列截断到 96 词，每个文件只保留 200 行\n",
        "import pandas as pd\n",
        "\n",
        "files = ['Colon_Cancer.csv', 'Liver_Cancer.csv', 'Lung_Cancer.csv', 'Stomach_Cancer.csv', 'Thyroid_Cancer.csv']\n",
        "text_col_name = 'cleaned_text'\n",
        "\n",
        "for fname in files:\n",
        "    try:\n",
        "        df = pd.read_csv(fname, encoding='utf-8', on_bad_lines='skip')\n",
        "    except FileNotFoundError:\n",
        "        print(f'未找到 {fname}，跳过')\n",
        "        continue\n",
        "    col = text_col_name if text_col_name in df.columns else df.columns[2]\n",
        "    # 第三列每行只保留前 96 词\n",
        "    df[col] = df[col].fillna('').astype(str).apply(lambda s: ' '.join(s.split()[:96]))\n",
        "    # 只保留前 200 行\n",
        "    df = df.head(200)\n",
        "    # 序号从 1 开始\n",
        "    df[df.columns[0]] = range(1, len(df) + 1)\n",
        "    df.to_csv(fname, index=False, encoding='utf-8')\n",
        "    print(f'{fname}: 第三列已截断为 96 词，保留 {len(df)} 行，已保存。')\n",
        "\n",
        "print('五个文件处理完成。')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
